# Background
- Main memory and registers are the only storage a CPU can access directly
- Memory unit only sees a stream of addresses + read request or addresses + data and write requests
- Main memory can tale many cycles - Cause stall
- Register access one cycle

# Protection 
- Process only access to the addresses in its address space where it lives in main memory
- provided by a pair of base and limit registers defining the logical address space of a process
- CPU must check every memory access generated in user mode - Ensure it is between base and limit
- This check is privileged 

# address binding
- Compiled code addresses bind to relocatable addresses
- Linker or loader will bind relocatable addresses to absolute addresses
- Each binding maps one address space to another

# Binding of instructions and data to memory
- Three different stages where it can happen
  - Compile time - Memory location known prior, absolute code, code my be recompiled if starting location changes
  - Load time - Generate relocatable code if memory location is not know at compile time 
  - Execution time - Binding delayed to run time if the process can be moved during its execution from memory segment to memory segment (hardware support needed)

# Logical vs. physical address space
- Logical address – generated by the CPU; also referred to as virtual address
- Physical address – address seen by the memory unit
- The same at compile-time, differs in execution time, due to address-binding scheme
- Logical address space is the set of all logical addresses generated by a program
- Physical address space is the set of all physical addresses generated by a program

# Memory management unit (MMU)
- Does nothing else than map a logical address from user-space to physical addresses hardware.
![[Pasted image 20230322144342.png]]

# Dynamic loading
- Entire program does not need to be in memory at one time 
- Routine not loaded until needed
- No special OS support is needed 
- Better memory utilization
- All routines kept on disk in relocatable load format

# Dynamic linking
- Static linking libraries and programs combined by loader into binary program image
- Dynamic linking - postponed until execution time
- A stub is used to locate appropriate memory-resident library routine
- Stub replaces itself with the address of the routine, and executes the routine
- Operating system checks if routine is in processes’ memory address - If not in address space, add to address space

# Contiguous Allocation
- Main memory must support both OS and user processes
- Limited resources must allocate efficiently
- Contiguous allocation - early method
- Main memory in two partitions
  - Resident operating system, usually held in low memory with interrupt vector
  - User processes then held in high memory
  - Each process contained in single contiguous section of memory
- Base register contains value of smallest physical address
- Limit register contains range of logical addresses – each logical address must be less than the limit register
- MMU maps logical address dynamically
- Can then allow actions such as kernel code being transient and kernel changing size

# Variable partition
- Degree of multiprogramming limited by number of partitions
- Variable-partition sizes for efficiency (sized to a given process’ needs)
- Hole – block of available memory; holes of various size are scattered throughout memory
- When a process arrives, it is allocated memory from a hole large enough to accommodate it
- Process exiting frees its partition, adjacent free partitions combined

# Dynamic storage allocation problem
- How to satisfy a request of size n from a list of free holes?
  - Best fit -> smallest hole big enough, least waste
  - First fit -> The first that fits is where it sits 
  - Worst fit -> largest hole big enough most waste 

# Fragmentation 
- External Fragmentation – total memory space exists to satisfy a request, but it is not contiguous
- Internal Fragmentation – allocated memory may be slightly larger than requested memory; this size difference is memory internal to a partition, but not being used
- First fit analysis reveals that given N blocks allocated, 0.5 N blocks lost to fragmentation - 0,33 may be unusable -> 50% rule
- Reduced fragmentation by compaction
  - memory contents placed together in one large block
  - Only possible if relocation is dynamic and done at execution time
  - I/O problem
    - Latch job in memory while it is involved in I/O
    - Do I/O only into OS buffers

# Paging
- Physical address space of a process can be non-contiguous; process is allocated physical memory whenever the latter is available
  - Avoids external fragmentation
  - Avoids problem of varying sized memory chunks
- Pages tables converts pages to frames
- Divide physical memory into fixed-sized blocks, frames
  - Size is power of 2, between 512 bytes and 16 Mbytes
- Divide logical memory into blocks of same size, pages
- Keep track of all free frames 
- Backing store likewise split into pages
- Still have Internal fragmentation

# Address Translation Scheme 
- Generated addresses divided into:
  - Page number (p) - used as index in page table for physical addresses  
  - Page offset (d) - combined with base address to define the physical memory address
  - address space $2^m$ and page size $2^n$
![[Pasted image 20230322151551.png]]


# Page table 
- Large array of pages kept in main memory
- Page-table base register (PTBR) points to the page table
- Page-table length register (PTLR) indicates size of the page table
- In this scheme every data/instruction access requires two memory accesses (Page table - data/instruction)
- The two memory access problem can be solved by the use of a special fast-lookup hardware cache called translation look-aside buffers (TLBs) (also called associative memory).

# Translation look-Aside buffer (TLB)
- Page number -> Frame number
- Very fast expensive hardware to does page lookups fast and efficiently
- address-space identifiers (ASIDs) uniquely identifies each process to provide address-space protection for that process - stored for each TLB entry - Otherwise flush needed after context switch
- Very small only 64 to 1024 entries
- TLB miss -> value is loaded into the TLB for faster access
  - Replacement policies must be considered
  - Some entries can be wired down for permanent fast access
### Hardware 
- Associative memory – parallel search
- Address translation (p, d)
  - If p is in associative register, get frame # out
  - Otherwise get frame # from page table in memory

# Effective access time example
![[Pasted image 20230322154502.png]]

# Memory protection
- Bit to show if the memory is read-only, write-only, execute-only etc.
- Valid-invalid bit attached to each entry in page table (valid -> page is in process, invalid -> page not in process) or use page-table length register (PTLR)
- Errors results in trap to kernel

# Valid or invalid bit in page table example
![[Pasted image 20230322154941.png]]

# Shared pages 
- Don't want to load the same library or something similar every time a process needs to use it so the page table entry is shared among the processes which may need it.
- Useful for inter-process communication if read-write pages sharing is allowed.
- Each process keeps a separate copy of the code and data
- Private data and code can appear anywhere in logical address space 

# Structure of the page table
- Memory structures for paging can get huge using straight-forward methods
- Consider a 32-bit logical address space as on modern computers
  - Page size -> 4KB
  - Page table 1 million entries
  - Each entry 4B -> 1 process 4MB
  - THIS BAD!

# Hierarchical page tables
- Break up the logical address space into multiple page tables
- A simple technique is a two-level page table
![[Pasted image 20230322160559.png]]

# Two level paging Example 
![[Pasted image 20230322160621.png]]
